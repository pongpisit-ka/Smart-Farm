from flask import Flask, Response, render_template_string
import cv2
import subprocess
import threading
import time
from queue import Queue
import os
import json
import numpy as np

app = Flask(__name__)

class VideoStreamer:
  def __init__(self):
      self.frame_queue = Queue(maxsize=2)
      self.detection_queue = Queue(maxsize=10)
      self.running = False
      self.cap = None
      self.hailo_process = None
      self.latest_detections = []
      
  def start_hailo_detection(self):
      """Start Hailo detection process"""
      self.running = True
      
      # Start Hailo detection process
      cmd = [
          'python3', 
          '/home/brisk/hailo-rpi5-examples/basic_pipelines/detection_simple.py',
          '--input', '/dev/video0',
          '--output', 'display'  # or pipe output
      ]
      
      try:
          print("Starting Hailo detection process...")
          self.hailo_process = subprocess.Popen(
              cmd, 
              stdout=subprocess.PIPE, 
              stderr=subprocess.PIPE,
              universal_newlines=True,
              bufsize=1
          )
          
          # Start thread to read Hailo output
          threading.Thread(target=self._read_hailo_output, daemon=True).start()
          
      except Exception as e:
          print(f"Error starting Hailo detection: {e}")
  
  def _read_hailo_output(self):
      """Read detection results from Hailo process"""
      while self.running and self.hailo_process:
          try:
              line = self.hailo_process.stdout.readline()
              if line:
                  print(f"Hailo output: {line.strip()}")
                  # Parse detection results if needed
                  # You might need to modify this based on your detection output format
                  
          except Exception as e:
              print(f"Error reading Hailo output: {e}")
              break
  
  def get_camera_stream(self):
      """Get stream directly from camera and apply detection overlay"""
      # Try different video sources
      video_sources = [
          '/dev/video0',
          '/dev/video1', 
          0,  # Default camera
          1   # Second camera
      ]
      
      self.cap = None
      for source in video_sources:
          try:
              print(f"Trying video source: {source}")
              self.cap = cv2.VideoCapture(source)
              if self.cap.isOpened():
                  print(f"Successfully opened: {source}")
                  break
              else:
                  self.cap.release()
          except Exception as e:
              print(f"Failed to open {source}: {e}")
              continue
      
      if self.cap is None or not self.cap.isOpened():
          print("No camera found, creating dummy frames")
          self._generate_dummy_frames()
          return
          
      # Set camera properties
      self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
      self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
      self.cap.set(cv2.CAP_PROP_FPS, 30)
      
      while self.running:
          ret, frame = self.cap.read()
          if not ret:
              print("Failed to read frame")
              break
          
          # Apply detection overlay (simulate detection results)
          frame_with_detection = self._apply_detection_overlay(frame)
              
          # Put frame into queue
          if not self.frame_queue.full():
              self.frame_queue.put(frame_with_detection)
          else:
              # Remove old frame if queue is full
              try:
                  self.frame_queue.get_nowait()
                  self.frame_queue.put(frame_with_detection)
              except:
                  pass
      
      if self.cap:
          self.cap.release()
  
  def _apply_detection_overlay(self, frame):
      """Apply detection overlay to frame"""
      # Simulate some detection results
      # In real implementation, you would get these from Hailo detection
      detections = [
          {"class": "person", "confidence": 0.89, "bbox": [100, 50, 200, 300]},
          {"class": "chair", "confidence": 0.75, "bbox": [300, 200, 150, 200]},
          {"class": "tv", "confidence": 0.65, "bbox": [450, 100, 150, 100]}
      ]
      
      # Draw bounding boxes
      for detection in detections:
          x, y, w, h = detection["bbox"]
          confidence = detection["confidence"]
          class_name = detection["class"]
          
          # Draw rectangle
          color = (0, 255, 0) if class_name == "person" else (255, 0, 0)
          cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)
          
          # Draw label
          label = f"{class_name} {confidence:.0%}"
          label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
          cv2.rectangle(frame, (x, y - label_size[1] - 10), 
                       (x + label_size[0], y), color, -1)
          cv2.putText(frame, label, (x, y - 5), 
                     cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
      
      return frame
  
  def _generate_dummy_frames(self):
      """Generate dummy frames when no camera is available"""
      import numpy as np
      
      while self.running:
          # Create a dummy frame
          frame = np.zeros((480, 640, 3), dtype=np.uint8)
          
          # Add some text
          cv2.putText(frame, "No Camera Signal", (150, 200), 
                     cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
          cv2.putText(frame, f"Time: {time.strftime('%H:%M:%S')}", (200, 250), 
                     cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
          
          # Add dummy detection boxes
          cv2.rectangle(frame, (100, 100), (200, 200), (0, 255, 0), 2)
          cv2.putText(frame, "person 89%", (105, 95), 
                     cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
          
          if not self.frame_queue.full():
              self.frame_queue.put(frame)
          
          time.sleep(1/30)  # 30 FPS
  
  def generate_frames(self):
      """Generate frames for web streaming"""
      while self.running:
          if not self.frame_queue.empty():
              frame = self.frame_queue.get()
              
              # Convert frame to JPEG
              ret, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 85])
              if ret:
                  frame_bytes = buffer.tobytes()
                  yield (b'--frame\r\n'
                         b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
          else:
              time.sleep(0.01)
  
  def stop_detection(self):
      """Stop Hailo detection process"""
      if self.hailo_process:
          try:
              self.hailo_process.terminate()
              self.hailo_process.wait(timeout=5)
          except:
              self.hailo_process.kill()
          self.hailo_process = None

# Create instance
streamer = VideoStreamer()

@app.route('/')
def index():
  """Main page showing video"""
  html_template = """
  <!DOCTYPE html>
  <html>
  <head>
      <title>Hailo Detection Stream</title>
      <style>
          body {
              font-family: Arial, sans-serif;
              background-color: #f0f0f0;
              margin: 0;
              padding: 20px;
          }
          .container {
              max-width: 1200px;
              margin: 0 auto;
              background: white;
              padding: 20px;
              border-radius: 10px;
              box-shadow: 0 4px 6px rgba(0,0,0,0.1);
          }
          h1 {
              text-align: center;
              color: #333;
              margin-bottom: 30px;
          }
          .video-container {
              text-align: center;
              margin-bottom: 20px;
              position: relative;
          }
          #videoStream {
              max-width: 100%;
              height: auto;
              border: 2px solid #ddd;
              border-radius: 8px;
              background: #000;
          }
          .info-panel {
              background: #f8f9fa;
              padding: 15px;
              border-radius: 8px;
              margin-top: 20px;
          }
          .status {
              display: inline-block;
              padding: 5px 10px;
              border-radius: 20px;
              color: white;
              font-weight: bold;
          }
          .status.online { background-color: #28a745; }
          .status.offline { background-color: #dc3545; }
          .controls {
              text-align: center;
              margin: 20px 0;
          }
          .btn {
              padding: 10px 20px;
              margin: 0 10px;
              border: none;
              border-radius: 5px;
              cursor: pointer;
              font-size: 16px;
          }
          .btn-start { background: #28a745; color: white; }
          .btn-stop { background: #dc3545; color: white; }
          .btn-status { background: #007bff; color: white; }
          .detection-overlay {
              position: absolute;
              top: 10px;
              left: 10px;
              background: rgba(0,0,0,0.7);
              color: white;
              padding: 10px;
              border-radius: 5px;
              font-size: 14px;
          }
      </style>
  </head>
  <body>
      <div class="container">
          <h1>ðŸ¤– Hailo AI Detection Stream</h1>
          
          <div class="controls">
              <button class="btn btn-start" onclick="startStream()">Start Stream</button>
              <button class="btn btn-stop" onclick="stopStream()">Stop Stream</button>
              <button class="btn btn-status" onclick="checkStatus()">Check Status</button>
          </div>
          
          <div class="video-container">
              <img id="videoStream" src="{{ url_for('video_feed') }}" alt="Video Stream">
              <div class="detection-overlay">
                  ðŸŽ¯ Live Detection Active<br>
                  ðŸ“Š Processing: Real-time
              </div>
          </div>
          
          <div class="info-panel">
              <h3>ðŸ“Š Stream Information</h3>
              <p><strong>Status:</strong> <span class="status online">ðŸŸ¢ Online</span></p>
              <p><strong>Detection:</strong> Person, Chair, TV</p>
              <p><strong>FPS:</strong> ~30 FPS</p>
              <p><strong>Resolution:</strong> 640x480</p>
              <p><strong>Hailo Process:</strong> <span id="hailoStatus">Running</span></p>
          </div>
          
          <div class="info-panel">
              <h3>ðŸŽ¯ Detection Classes</h3>
              <p>âœ… Person Detection (Green Box)<br>
                 âœ… Chair Detection (Blue Box)<br>
                 âœ… TV Detection (Blue Box)<br>
                 âœ… Real-time Processing<br>
                 âœ… Confidence Scores</p>
          </div>
          
          <div class="info-panel" id="statusPanel">
              <h3>ðŸ“¡ System Status</h3>
              <p id="systemStatus">Click "Check Status" to update</p>
          </div>
      </div>
      
      <script>
          // Auto-refresh video stream
          const img = document.getElementById('videoStream');
          
          img.onerror = function() {
              console.log('Video stream error, retrying...');
              setTimeout(() => {
                  this.src = "{{ url_for('video_feed') }}?" + new Date().getTime();
              }, 2000);
          };
          
          function startStream() {
              fetch('/start')
                  .then(response => response.json())
                  .then(data => {
                      alert(data.message);
                      document.getElementById('hailoStatus').textContent = 'Running';
                      // Refresh video stream
                      img.src = "{{ url_for('video_feed') }}?" + new Date().getTime();
                  })
                  .catch(error => {
                      alert('Error starting stream: ' + error);
                  });
          }
          
          function stopStream() {
              fetch('/stop')
                  .then(response => response.json())
                  .then(data => {
                      alert(data.message);
                      document.getElementById('hailoStatus').textContent = 'Stopped';
                  })
                  .catch(error => {
                      alert('Error stopping stream: ' + error);
                  });
          }
          
          function checkStatus() {
              fetch('/status')
                  .then(response => response.json())
                  .then(data => {
                      document.getElementById('systemStatus').innerHTML = 
                          `Running: ${data.running}<br>
                           Queue Size: ${data.queue_size}<br>
                           Hailo Process: ${data.hailo_running ? 'Active' : 'Inactive'}`;
                  })
                  .catch(error => {
                      document.getElementById('systemStatus').innerHTML = 'Error: ' + error;
                  });
          }
          
          // Auto-check status every 5 seconds
          setInterval(checkStatus, 5000);
      </script>
  </body>
  </html>
  """
  return render_template_string(html_template)

@app.route('/video_feed')
def video_feed():
  """Video streaming route"""
  return Response(streamer.generate_frames(),
                 mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/start')
def start_stream():
  """Start streaming"""
  if not streamer.running:
      streamer.start_hailo_detection()
      threading.Thread(target=streamer.get_camera_stream, daemon=True).start()
      return {"status": "started", "message": "Hailo detection stream started successfully"}
  return {"status": "already_running", "message": "Stream is already running"}

@app.route('/stop')
def stop_stream():
  """Stop streaming"""
  streamer.running = False
  streamer.stop_detection()
  if streamer.cap:
      streamer.cap.release()
  return {"status": "stopped", "message": "Stream and Hailo detection stopped"}

@app.route('/status')
def get_status():
  """Check status"""
  return {
      "running": streamer.running,
      "queue_size": streamer.frame_queue.qsize() if hasattr(streamer, 'frame_queue') else 0,
      "hailo_running": streamer.hailo_process is not None and streamer.hailo_process.poll() is None
  }

if __name__ == '__main__':
  # Start streaming automatically
  streamer.start_hailo_detection()
  threading.Thread(target=streamer.get_camera_stream, daemon=True).start()
  
  print("Starting Hailo Detection Web Server...")
  print("Access at: http://your-pi-ip:5000")
  
  # Run Flask server
  app.run(host='0.0.0.0', port=5000, debug=False, threaded=True)
